{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "SCRIPT_DIR = os.path.dirname(os.path.abspath(\".\"))\n",
        "sys.path.append(SCRIPT_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from trainer.models import ldm\n",
        "from torchvision import transforms, datasets\n",
        "from utils.loader import ConfigKey, DataloaderConfig, DatasetLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NotebookLoader(DatasetLoader):\n",
        "    def get_transform(self):\n",
        "        args = self.args\n",
        "\n",
        "        def dequantize(x, nvals=256):\n",
        "            \"\"\"[0, 1] -> [0, nvals] -> add uniform noise -> [0, 1]\"\"\"\n",
        "            noise = x.new().resize_as_(x).uniform_()\n",
        "            x = x * (nvals - 1) + noise\n",
        "            x = x / nvals\n",
        "            return x\n",
        "\n",
        "        transform = transforms.Compose(\n",
        "            [\n",
        "                # transforms.RandomResizedCrop(args.img_size, scale=(0.8, 1.0)),\n",
        "                transforms.Resize((args.img_size, args.img_size)),\n",
        "                transforms.ToTensor(),\n",
        "                # transforms.Normalize((0.5,), (0.5,)),\n",
        "                dequantize,\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        return transform\n",
        "\n",
        "    def get_dataloader_configs(self):\n",
        "        args = self.args\n",
        "\n",
        "        dataset = datasets.MNIST(\n",
        "            args.dataset_path,\n",
        "            transform=self.get_transform(),\n",
        "            download=True,\n",
        "        )\n",
        "        config = DataloaderConfig(\n",
        "            dataset=dataset,\n",
        "            batch_size=args.batch_size,\n",
        "            shuffle=args.shuffle,\n",
        "        )\n",
        "\n",
        "        return {ConfigKey.train: config}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ldm_trainer = ldm.LDMTrainer()\n",
        "args = ldm_trainer.args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "args.model_type = \"sde\"\n",
        "args.img_size = 32\n",
        "args.in_channels = 1\n",
        "args.z_channels = 32\n",
        "args.batch_size = 256\n",
        "args.shuffle = True\n",
        "args.save_freq = 2\n",
        "args.dataset_path = \"./data\"\n",
        "args.beta_min = 0.1\n",
        "args.beta_max = 1\n",
        "args.num_classes = 10\n",
        "args.loader = NotebookLoader\n",
        "args.vae_checkpoint = \"ckpt-100.pt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ldm_trainer.train()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
